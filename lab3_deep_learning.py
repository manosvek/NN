# -*- coding: utf-8 -*-
"""NN_team08_lab3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Iye7ILS20XzagSmFc9YEc5QUDO1pxxU

# 3η Εργαστηριακή Άσκηση: **Βαθιά μάθηση στο CIFAR-100**
---
**Ομάδα 08** \\
Βεκράκης Εμμανουήλ - 03116068 \\
Κρανιάς Δημήτριος - 03116030 \\
Μισιακός Παναγιώτης - 03116351 \\

## Βασικές συμπεριλήψεις

### Εγκατάσταση απαραίτητων πακέτων
"""

# All packages that we need
!pip install pip --upgrade #upgrade pip package installer
!pip install keras --upgrade #upgrade keras package
!pip install tensorflow --upgrade #upgrade tensorflow package
!pip install numpy --upgrade #upgrade numpy package
!pip install pandas --upgrade #upgrade pandas package
!pip install matplotlib==3.1.3 #upgrade matplotlib package

"""### Σύνδεση με Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""### Βιβλιοθήκες και βασικές συναρτήσεις"""

from __future__ import absolute_import, division, print_function, unicode_literals # legacy compatibility

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import EfficientNetB0

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# helper functions

# select from from_list elements with index in index_list
def select_from_list(from_list, index_list):
  filtered_list= [from_list[i] for i in index_list]
  return(filtered_list)

# append in filtered_list the index of each element of unfilterd_list if it exists in in target_list
def get_ds_index(unfiltered_list, target_list):
  index = 0
  filtered_list=[]
  for i_ in unfiltered_list:
    if i_[0] in target_list:
      filtered_list.append(index)
    index += 1
  return(filtered_list)

# select a url for a unique subset of CIFAR-100 with 20, 40, 60, or 80 classes
def select_classes_number(classes_number = 20):
  cifar100_20_classes_url = "https://pastebin.com/raw/nzE1n98V"
  cifar100_40_classes_url = "https://pastebin.com/raw/zGX4mCNP"
  cifar100_60_classes_url = "https://pastebin.com/raw/nsDTd3Qn"
  cifar100_80_classes_url = "https://pastebin.com/raw/SNbXz700"
  if classes_number == 20:
    return cifar100_20_classes_url
  elif classes_number == 40:
    return cifar100_40_classes_url
  elif classes_number == 60:
    return cifar100_60_classes_url
  elif classes_number == 80:
    return cifar100_80_classes_url
  else:
    return -1

"""## Εισαγωγή και επισκόπηση του συνόλου δεδομένων"""

# load the entire dataset
(x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.cifar100.load_data(label_mode='fine')

print(x_train_all.shape)

"""Η κάθε ομάδα θα δουλέψει με ένα μοναδικό ξεχωριστό υποσύνολο του CIFAR-100
Στο επόμενο κελί, αντικαταστήστε την τιμή της μεταβλητής `team_seed` με τον αριθμό της ομάδας σας.
"""

# Our team seed number
team_seed = 8

"""Στο επόμενο κελί μπορείτε να διαλέξετε το πλήθος των κατηγορίων σας: 20 (default), 40, 60 ή 80."""

# select the number of classes
cifar100_classes_url = select_classes_number(80)

"""Δημιουργούμε το μοναδικό dataset της ομάδας μας:"""

team_classes = pd.read_csv(cifar100_classes_url, sep=',', header=None)
CIFAR100_LABELS_LIST = pd.read_csv('https://pastebin.com/raw/qgDaNggt', sep=',', header=None).astype(str).values.tolist()[0]

our_index = team_classes.iloc[team_seed,:].values.tolist()
our_classes = select_from_list(CIFAR100_LABELS_LIST, our_index)
train_index = get_ds_index(y_train_all, our_index)
test_index = get_ds_index(y_test_all, our_index)

x_train_ds = np.asarray(select_from_list(x_train_all, train_index))
y_train_ds = np.asarray(select_from_list(y_train_all, train_index))
x_test_ds = np.asarray(select_from_list(x_test_all, test_index))
y_test_ds = np.asarray(select_from_list(y_test_all, test_index))

# print our classes
print(our_classes)

# get (train) dataset dimensions
data_size, img_rows, img_cols, img_channels = x_train_ds.shape

# set validation set percentage (wrt the training set size)
validation_percentage = 0.15
val_size = round(validation_percentage * data_size)

# Reserve val_size samples for validation
x_val = x_train_ds[-val_size:]/255
y_val = y_train_ds[-val_size:]
x_train = x_train_ds[:-val_size]/255
y_train = y_train_ds[:-val_size]
x_test = x_test_ds/255
y_test = y_test_ds

# summarize loaded dataset
print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))
print('Validation: X=%s, y=%s' % (x_val.shape, y_val.shape))
print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))

# get class label from class index
def class_label_from_index(fine_category):
  return(CIFAR100_LABELS_LIST[fine_category.item(0)])

# plot first few images
plt.figure(figsize=(6, 6))
for i in range(9):
	# define subplot
  plt.subplot(330 + 1 + i).set_title(class_label_from_index(y_train[i]))
	# plot raw pixel data
  plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))
  #show the figure
plt.show()

"""## Διαχείριση μνήμης - TFRecords
Για να αποφύγουμε την υπερβολική χρήση της RAM για αποθήκευση μετασχηματισμένων δεδομένων (όπως πχ images 224x224 που είναι ένα καλό νούμερο διαστάσεων για το EfficientNet B0 που θα δούμε παρακάτω), χρησιμοποιούμε το format TFRecords.
"""

directory = "/content/drive/My Drive/Νευρωνικά/3η Εργασία/tfrecords/"

"""### Βοηθητικές Συναρτήσεις"""

def _bytes_feature(value):
  """Returns a bytes_list from a string / byte."""
  if isinstance(value, type(tf.constant(0))):
    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def _int64_feature(value):
  """Returns an int64_list from a bool / enum / int / uint."""
  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

#These examples use scalar inputs. To convert tensors to binary strings we will use tf.io.serialize_tensor
#To convert them back to tensors we will use tf.io.parse_tensor

"""### Serialization / Deserialization"""

def serialize_example(image, label, shape):
  feature = {
      'height': _int64_feature(shape[0]),
      'width': _int64_feature(shape[1]),
      'depth': _int64_feature(shape[2]),
      'label': _int64_feature(label),
      'image_string': _bytes_feature(image)
  }

  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
  return example_proto.SerializeToString()

def tfr_writer(directory, X, y):
  with tf.io.TFRecordWriter(directory) as writer:
    for image, label in zip(X, y):
      #We use bicubic interpolation because it is one of the best when upsampling images
      resized_image = tf.image.resize(image, [IMAGE_SHAPE[0], IMAGE_SHAPE[1]], method=tf.image.ResizeMethod.BICUBIC)

      image_string = tf.io.serialize_tensor(resized_image)
      shape = resized_image.shape

      example = serialize_example(image_string, label, shape)
      writer.write(example)

def _parse_function(example_proto):
  image_feature_description = {
      'height': tf.io.FixedLenFeature([], tf.int64),
      'width': tf.io.FixedLenFeature([], tf.int64),
      'depth': tf.io.FixedLenFeature([], tf.int64),
      'label': tf.io.FixedLenFeature([], tf.int64),
      'image_string': tf.io.FixedLenFeature([], tf.string)
  }

  example = tf.io.parse_single_example(example_proto, image_feature_description)

  image = tf.io.parse_tensor(example['image_string'], float)
  label = example['label']
  shape = IMAGE_SHAPE
  image = tf.reshape(image, shape)

  return image, [label]
  
def tfr_reader(directory):
  dataset = tf.data.TFRecordDataset(directory)
  return dataset.map(_parse_function)

"""### Serializing the data"""

IMAGE_SHAPE = (64, 64, 3)

tfr_writer(directory + "train64.tfrecords", x_train, y_train)
tfr_writer(directory + "val64.tfrecords", x_val, y_val)
tfr_writer(directory + "test64.tfrecords", x_test, y_test)

IMAGE_SHAPE = (96, 96, 3)

tfr_writer(directory + "train96.tfrecords", x_train, y_train)
tfr_writer(directory + "val96.tfrecords", x_val, y_val)
tfr_writer(directory + "test96.tfrecords", x_test, y_test)

IMAGE_SHAPE = (128, 128, 3)

tfr_writer(directory + "train128.tfrecords", x_train, y_train)
tfr_writer(directory + "val128.tfrecords", x_val, y_val)
tfr_writer(directory + "test128.tfrecords", x_test, y_test)

"""### Deserializing the data"""

IMAGE_SHAPE = (64, 64, 3)

#Reading the datasets that contain 64x64 images
train_ds_64 = tfr_reader(directory + "train64.tfrecords")
val_ds_64 = tfr_reader(directory + "val64.tfrecords")
test_ds_64 = tfr_reader(directory + "test64.tfrecords")

IMAGE_SHAPE = (96, 96, 3)

#Reading the datasets that contain 64x64 images
train_ds_96 = tfr_reader(directory + "train96.tfrecords")
val_ds_96 = tfr_reader(directory + "val96.tfrecords")
test_ds_96 = tfr_reader(directory + "test96.tfrecords")

IMAGE_SHAPE = (128, 128, 3)

#Reading the datasets that contain 64x64 images
train_ds_128 = tfr_reader(directory + "train128.tfrecords")
val_ds_128 = tfr_reader(directory + "val128.tfrecords")
test_ds_128 = tfr_reader(directory + "test128.tfrecords")

def get_prefetched_data(batch_size=64, img_size=32):
  if img_size == 32:
    train_ds =_input_fn_slices(x_train, y_train, batch_size) #PrefetchDataset object
    validation_ds =_input_fn_slices(x_val, y_val, batch_size) #PrefetchDataset object
    test_ds =_input_fn_slices(x_test, y_test, batch_size) #PrefetchDataset object

  elif img_size == 64:
    train_ds =_input_fn(train_ds_64, batch_size) 
    validation_ds =_input_fn(val_ds_64, batch_size)
    test_ds =_input_fn(test_ds_64, batch_size)

  elif img_size == 96:
    train_ds =_input_fn(train_ds_96, batch_size) 
    validation_ds =_input_fn(val_ds_96, batch_size)
    test_ds =_input_fn(test_ds_96, batch_size)

  else:
    train_ds =_input_fn(train_ds_128, batch_size) 
    validation_ds =_input_fn(val_ds_128, batch_size)
    test_ds =_input_fn(test_ds_128, batch_size)
    
  return train_ds, validation_ds, test_ds

"""## Βοηθητικές Συναρτήσεις

### Συναρτήσεις εκπαίδευσης

Θα χρησιμοποιήσουμε την ιδιότητα data prefetch του tf2:
"""

# we user prefetch https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch 
# see also AUTOTUNE
# the dataset is now "infinite"

BATCH_SIZE = 128
AUTOTUNE = tf.data.experimental.AUTOTUNE # https://www.tensorflow.org/guide/data_performance

def _input_fn(ds, BATCH_SIZE):
  ds = ds.shuffle(buffer_size=data_size)
  ds = ds.repeat()
  ds = ds.batch(BATCH_SIZE)
  ds = ds.prefetch(buffer_size=AUTOTUNE)
  return ds

def _input_fn_slices(x, y, BATCH_SIZE):
  ds = tf.data.Dataset.from_tensor_slices((x, y))
  ds = ds.shuffle(buffer_size=data_size)
  ds = ds.repeat()
  ds = ds.batch(BATCH_SIZE)
  ds = ds.prefetch(buffer_size=AUTOTUNE)
  return ds

# steps_per_epoch and validation_steps for training and validation: https://www.tensorflow.org/guide/keras/train_and_evaluate

def train_model(model, epochs = 10, steps_per_epoch = 2, validation_steps = 1, augment = False):
  #Early Stopping Callback
  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
  #Learning Rate Reduction
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)
  #The callback function
  callback = [early_stopping, reduce_lr]

  history = model.fit(train_ds, epochs=epochs, callbacks=callback, steps_per_epoch=steps_per_epoch, validation_data=validation_ds, validation_steps=validation_steps)
  return history

"""### Γραφικές παραστάσεις εκπαίδευσης και απόδοση στο σύνολο ελέγχου"""

# plot diagnostic learning curves
def summarize_diagnostics(history):
	plt.figure(figsize=(8, 8))
	plt.suptitle('Training Curves')
	# plot loss
	plt.subplot(211)
	plt.title('Cross Entropy Loss')
	plt.plot(history.history['loss'], color='blue', label='train')
	plt.plot(history.history['val_loss'], color='orange', label='val')
	plt.legend(loc='upper right')
	# plot accuracy
	plt.subplot(212)
	plt.title('Classification Accuracy')
	plt.plot(history.history['accuracy'], color='blue', label='train')
	plt.plot(history.history['val_accuracy'], color='orange', label='val')
	plt.legend(loc='lower right')
	return plt
 
# print test set evaluation metrics
def model_evaluation(model, evaluation_steps):
	print('\nTest set evaluation metrics')
	loss0,accuracy0 = model.evaluate(test_ds, steps = evaluation_steps)
	print("loss: {:.2f}".format(loss0))
	print("accuracy: {:.2f}".format(accuracy0))

def model_report(model, history, evaluation_steps = 10):
	plt = summarize_diagnostics(history)
	plt.show()
	model_evaluation(model, evaluation_steps)

"""### Επαύξηση δεδομένων

"""

def data_augmentation(shape):
  augment = tf.keras.Sequential([
      layers.experimental.preprocessing.RandomFlip("horizontal", input_shape=(shape,shape,3)),
      layers.experimental.preprocessing.RandomRotation(0.1),
      layers.experimental.preprocessing.RandomZoom(0.1)
  ])
  return augment

"""## Μοντέλα δικτύων

### Ένα μικρό συνελικτικό δίκτυο "from scratch"
"""

# a simple CNN https://www.tensorflow.org/tutorials/images/cnn

def init_simple_model(summary, img_shape, optimizer):
  model = tf.keras.Sequential([
          layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_shape, img_shape, 3)),
          layers.MaxPooling2D((2, 2)),
          layers.Conv2D(64, (3, 3), activation='relu'),
          layers.MaxPooling2D((2, 2)),
          layers.Conv2D(128, (3, 3), activation='relu'),
          layers.Flatten(),
          layers.Dense(64, activation='relu'),
          layers.Dense(100, activation='softmax')
  ])
  
  model.compile(optimizer=optimizer, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
  if summary: 
    model.summary()
  return model

simple_cnn_fit_times = []
simple_cnn_acc = []
sizes = [(64, 32), (128, 32), (256, 32), (64, 64), (128, 64), (256, 64)]
lr=1e-3

for (batch_size, img_size) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  SIMPLE_MODEL = init_simple_model(True, img_size, tf.optimizers.Adam(learning_rate=lr))

  start = time.process_time()
  SIMPLE_MODEL_history = train_model(SIMPLE_MODEL, 50, 30, 5)
  loss, accuracy = model_report(SIMPLE_MODEL, SIMPLE_MODEL_history, 30)

  simple_cnn_acc.append(accuracy)
  simple_cnn_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(simple_cnn_acc)
print(simple_cnn_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * simple_cnn_acc[i]))

simple_cnn_fit_times = []
simple_cnn_acc = []
sizes = [(64, 96), (128, 96), (256, 96)]
lr=1e-3

for (batch_size, img_size) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  SIMPLE_MODEL = init_simple_model(True, img_size, tf.optimizers.Adam(learning_rate=lr))

  start = time.process_time()
  SIMPLE_MODEL_history = train_model(SIMPLE_MODEL, 50, 30, 5)
  loss, accuracy = model_report(SIMPLE_MODEL, SIMPLE_MODEL_history, 30)

  simple_cnn_acc.append(accuracy)
  simple_cnn_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(simple_cnn_acc)
print(simple_cnn_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * simple_cnn_acc[i]))

simple_cnn_acc = []
batch_size, img_size = (256, 64)

# optimizers = #[tf.optimizers.Adam(learning_rate=5e-4),
optimizers =  [tf.optimizers.SGD(learning_rate=1e-2), tf.optimizers.SGD(learning_rate=5e-3),
              tf.optimizers.Nadam(learning_rate=1e-3), tf.optimizers.Nadam(learning_rate=5e-4)]

train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

for optimizer in optimizers:
  SIMPLE_MODEL = init_simple_model(True, img_size, optimizer)
  SIMPLE_MODEL_history = train_model(SIMPLE_MODEL, 50, 30, 5)

  loss, accuracy = model_report(SIMPLE_MODEL, SIMPLE_MODEL_history, 30)
  simple_cnn_acc.append(accuracy)

print(simple_cnn_acc)

"""### Μεταφορά μάθησης: VGG$16$"""

# transfer learning: VGG16 trained on ImageNet without the top layer

def init_VGG16_model(summary, img_size, dropout=0.5, optimal=True):
  vgg_model=tf.keras.applications.VGG16(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')
  
  VGG16_MODEL=vgg_model.layers[0](vgg_model)
  # unfreeze conv layers
  VGG16_MODEL.trainable=True

  if (optimal):
    model = tf.keras.Sequential([
            data_augmentation(img_size),
            VGG16_MODEL,
            layers.Dropout(dropout),
            layers.GlobalAveragePooling2D(),       
            layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])

  else:
    model = tf.keras.Sequential([
            VGG16_MODEL,
            layers.GlobalAveragePooling2D(),       
            layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])

  model.compile(optimizer=tf.optimizers.Adam(learning_rate=5e-5), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
  if summary: 
    model.summary()
  return model

vgg16_fit_times = []
vgg16_acc = []
sizes = [(128, 32, 0.5), (256, 32, 0.5), (64, 64, 0.5), (256, 64, 0.5)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  VGG16_MODEL = init_VGG16_model(True, img_size, dropout)

  start = time.process_time()
  VGG16_MODEL_history = train_model(VGG16_MODEL, 200, 40, 10)
  loss, accuracy = model_report(VGG16_MODEL, VGG16_MODEL_history, 30)

  vgg16_acc.append(accuracy)
  vgg16_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(vgg16_acc)
print(vgg16_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * vgg16_acc[i]))

vgg16_fit_times = []
vgg16_acc = []
sizes = [(64, 32, 0.2), (64, 32, 0.5), (128, 64, 0.2), (128, 64, 0.5)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]
lr=5e-5

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  VGG16_MODEL = init_VGG16_model(True, img_size, dropout)

  start = time.process_time()
  VGG16_MODEL_history = train_model(VGG16_MODEL, 200, 40, 10)
  loss, accuracy = model_report(VGG16_MODEL, VGG16_MODEL_history, 30)

  vgg16_acc.append(accuracy)
  vgg16_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(vgg16_acc)
print(vgg16_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * vgg16_acc[i]))

vgg16_fit_times = []
vgg16_acc = []
sizes = [(64, 96, 0.5), (128, 96, 0.5)]
lr=5e-5

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  VGG16_MODEL = init_VGG16_model(True, img_size, tf.optimizers.Adam(learning_rate=lr), dropout)

  start = time.process_time()
  VGG16_MODEL_history = train_model(VGG16_MODEL, 200, 40, 10)
  loss, accuracy = model_report(VGG16_MODEL, VGG16_MODEL_history, 30)

  vgg16_acc.append(accuracy)
  vgg16_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(vgg16_acc)
print(vgg16_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * vgg16_acc[i]))

vgg16_fit_times = []
vgg16_acc = []
sizes = [(256, 96, 0.5)]
lr=5e-5

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  VGG16_MODEL = init_VGG16_model(True, img_size, dropout)

  start = time.process_time()
  VGG16_MODEL_history = train_model(VGG16_MODEL, 200, 40, 10)
  loss, accuracy = model_report(VGG16_MODEL, VGG16_MODEL_history, 30)

  vgg16_acc.append(accuracy)
  vgg16_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(vgg16_acc)
print(vgg16_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * vgg16_acc[i]))

vgg16_fit_times = []
vgg16_acc = []
sizes = [(128, 32, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  VGG16_MODEL = init_VGG16_model(True, img_size, dropout, optimal=False)

  start = time.process_time()
  VGG16_MODEL_history = train_model(VGG16_MODEL, 200, 40, 10)
  loss, accuracy = model_report(VGG16_MODEL, VGG16_MODEL_history, 30)

  vgg16_acc.append(accuracy)
  vgg16_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(vgg16_acc)
print(vgg16_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * vgg16_acc[i]))

"""### Μεταφορά μάθησης: Xception"""

def init_Xception_model(summary, shape, dropout=0.5, optimal=True, trainable=True):
  xception_model=tf.keras.applications.Xception(input_shape=(shape, shape, 3), include_top=False, weights='imagenet')

  xception_model.trainable=trainable

  if (optimal):
    model = tf.keras.Sequential([
            data_augmentation(shape),
            xception_model,
            layers.Dropout(dropout),
            layers.GlobalAveragePooling2D(),       
            layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])

  else:
    model = tf.keras.Sequential([
            xception_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])

  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.00005), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
  if summary: 
    model.summary()
  return model

xception_fit_times = []
xception_acc = []
sizes = [(64, 96, 0.2), (128, 96, 0.2),  (256, 96, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  XCEPTION_MODEL = init_Xception_model(True, img_size, dropout)

  start = time.process_time()
  XCEPTION_MODEL_history = train_model(XCEPTION_MODEL, 200, 40, 10)
  loss, accuracy = model_report(XCEPTION_MODEL, XCEPTION_MODEL_history, 30)

  xception_acc.append(accuracy)
  xception_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(xception_acc)
print(xception_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * xception_acc[i]))

xception_fit_times = []
xception_acc = []
sizes = [(64, 96, 0.2), (128, 96, 0.2),  (256, 96, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  XCEPTION_MODEL = init_Xception_model(True, img_size, dropout, trainable=False)

  start = time.process_time()
  XCEPTION_MODEL_history = train_model(XCEPTION_MODEL, 200, 40, 10)
  loss, accuracy = model_report(XCEPTION_MODEL, XCEPTION_MODEL_history, 30)

  xception_acc.append(accuracy)
  xception_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(xception_acc)
print(xception_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * xception_acc[i]))

xception_fit_times = []
xception_acc = []
sizes = [(64, 96, 0.5), (128, 96, 0.5),  (256, 96, 0.5)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  XCEPTION_MODEL = init_Xception_model(True, img_size, dropout, trainable=False)

  start = time.process_time()
  XCEPTION_MODEL_history = train_model(XCEPTION_MODEL, 200, 40, 10)
  loss, accuracy = model_report(XCEPTION_MODEL, XCEPTION_MODEL_history, 30)

  xception_acc.append(accuracy)
  xception_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(xception_acc)
print(xception_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * xception_acc[i]))

xception_fit_times = []
xception_acc = []
sizes = [(128, 96, 0.5)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  XCEPTION_MODEL = init_Xception_model(True, img_size, dropout, optimal=False)

  start = time.process_time()
  XCEPTION_MODEL_history = train_model(XCEPTION_MODEL, 200, 40, 10)
  loss, accuracy = model_report(XCEPTION_MODEL, XCEPTION_MODEL_history, 30)

  xception_acc.append(accuracy)
  xception_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(xception_acc)
print(xception_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * xception_acc[i]))

"""### EfficientNet $Β0$"""

def init_EfficientNet_B0_model(summary, shape, dropout=0.5, optimal=True, trainable=True):
  effnet_model = tf.keras.applications.EfficientNetB0(input_shape=(shape,shape,3), include_top=False, weights='imagenet')

  effnet_model.trainable = trainable
  if (optimal):
    model = tf.keras.Sequential([
          data_augmentation(shape),
          effnet_model,
          layers.Dropout(dropout),
          layers.GlobalAveragePooling2D(),       
          layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])

  else:
    model = tf.keras.Sequential([
            effnet_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])
    

  model.compile(optimizer=tf.optimizers.Adam(learning_rate=2e-5), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
  if summary: 
    model.summary()
  return model

effnet_fit_times = []
effnet_acc = []
sizes = [(64, 32, 0.2), (128, 32, 0.2),  (256, 32, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  EfficientNet_B0_MODEL = init_EfficientNet_B0_model(True, img_size, dropout)

  start = time.process_time()
  EfficientNet_B0_history = train_model(EfficientNet_B0_MODEL, 200, 40, 10)
  loss, accuracy = model_report(EfficientNet_B0_MODEL, EfficientNet_B0_history, 30)

  effnet_acc.append(accuracy)
  effnet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(effnet_acc)
print(effnet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * effnet_acc[i]))

effnet_fit_times = []
effnet_acc = []
sizes = [(64, 64, 0.2), (128, 64, 0.2),  (256, 64, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  EfficientNet_B0_MODEL = init_EfficientNet_B0_model(True, img_size, dropout)

  start = time.process_time()
  EfficientNet_B0_history = train_model(EfficientNet_B0_MODEL, 200, 40, 10)
  loss, accuracy = model_report(EfficientNet_B0_MODEL, EfficientNet_B0_history, 30)

  effnet_acc.append(accuracy)
  effnet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(effnet_acc)
print(effnet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * effnet_acc[i]))

effnet_fit_times = []
effnet_acc = []
sizes = [(64, 96, 0.2), (128, 96, 0.2),  (256, 96, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  EfficientNet_B0_MODEL = init_EfficientNet_B0_model(True, img_size, dropout)

  start = time.process_time()
  EfficientNet_B0_history = train_model(EfficientNet_B0_MODEL, 200, 40, 10)
  loss, accuracy = model_report(EfficientNet_B0_MODEL, EfficientNet_B0_history, 30)

  effnet_acc.append(accuracy)
  effnet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(effnet_acc)
print(effnet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * effnet_acc[i]))

effnet_fit_times = []
effnet_acc = []
sizes = [(64, 32, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  EfficientNet_B0_MODEL = init_EfficientNet_B0_model(True, img_size, dropout, optimal=False)

  start = time.process_time()
  EfficientNet_B0_history = train_model(EfficientNet_B0_MODEL, 200, 40, 10)
  loss, accuracy = model_report(EfficientNet_B0_MODEL, EfficientNet_B0_history, 30)

  effnet_acc.append(accuracy)
  effnet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(effnet_acc)
print(effnet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * effnet_acc[i]))

"""### DenseNet$201$

"""

def init_DenseNet_model(summary, shape, dropout=0.5, optimal=True, trainable=True):
  densenet_model = tf.keras.applications.DenseNet201(input_shape=(shape,shape,3), include_top=False, weights='imagenet')

  densenet_model.trainable = trainable
  if (optimal):
    model = tf.keras.Sequential([
          data_augmentation(shape),
          densenet_model,
          layers.Dropout(dropout),
          layers.GlobalAveragePooling2D(),       
          layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])

  else:
    model = tf.keras.Sequential([
            densenet_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(len(CIFAR100_LABELS_LIST), activation='softmax')
    ])
    

  model.compile(optimizer=tf.optimizers.Adam(learning_rate=5e-5), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
  if summary: 
    model.summary()
  return model

densenet_fit_times = []
densenet_acc = []
sizes = [(64, 96, 0.2), (128, 32, 0.2),  (256, 96, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  DenseNet_MODEL = init_DenseNet_model(True, img_size, dropout)

  start = time.process_time()
  DenseNet_history = train_model(DenseNet_MODEL, 200, 40, 10)
  loss, accuracy = model_report(DenseNet_MODEL, DenseNet_history, 30)

  densenet_acc.append(accuracy)
  densenet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(densenet_acc)
print(densenet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * densenet_acc[i]))

densenet_fit_times = []
densenet_acc = []
sizes = [(64, 64, 0.2), (128, 64, 0.2),  (256, 64, 0.2), (128, 96, 0.2)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  DenseNet_MODEL = init_DenseNet_model(True, img_size, dropout)

  start = time.process_time()
  DenseNet_history = train_model(DenseNet_MODEL, 200, 40, 10)
  loss, accuracy = model_report(DenseNet_MODEL, DenseNet_history, 30)

  densenet_acc.append(accuracy)
  densenet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(densenet_acc)
print(densenet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * densenet_acc[i]))

# Learning rate 5e-5
densenet_fit_times = []
densenet_acc = []
sizes = [(64, 96, 0.5), (128, 96, 0.5),  (256, 96, 0.5)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  DenseNet_MODEL = init_DenseNet_model(True, img_size, dropout)

  start = time.process_time()
  DenseNet_history = train_model(DenseNet_MODEL, 200, 40, 10)
  loss, accuracy = model_report(DenseNet_MODEL, DenseNet_history, 30)

  densenet_acc.append(accuracy)
  densenet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(densenet_acc)
print(densenet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * densenet_acc[i]))

# Learning rate 5e-5
densenet_fit_times = []
densenet_acc = []
sizes = [(64, 32, 0.5)]
# sizes = [(64, 96, 0.5), (64, 96, 0.5), (256, 96, 0.5)]

for (batch_size, img_size, dropout) in sizes:
  train_ds, validation_ds, test_ds = get_prefetched_data(batch_size, img_size)

  DenseNet_MODEL = init_DenseNet_model(True, img_size, dropout, optimal=False)

  start = time.process_time()
  DenseNet_history = train_model(DenseNet_MODEL, 200, 40, 10)
  loss, accuracy = model_report(DenseNet_MODEL, DenseNet_history, 30)

  densenet_acc.append(accuracy)
  densenet_fit_times.append('{:.2f}'.format(1000 * (time.process_time() - start)))

print(densenet_acc)
print(densenet_fit_times)

for i in range(len(sizes)):
  print('$({',sizes[i][1],'},{',sizes[i][1],'}, 3)$ & ${',sizes[i][0],'}$ & Adam & 1\cdot10^{-3} & ', '{:.2f}\%\\\\'.format(100 * densenet_acc[i]))

"""## Τελική Σύγκριση Μοντέλων"""

fig, ax = plt.subplots()
x = range(3)
ax.plot(x, [33.53, 38.03, 33.15], marker='o', linestyle='--', label='Simple CNN')
ax.plot(x, [60.77, 73.91, 76.51], marker='p', linestyle='--', label='VGG16')
ax.plot(x, [1.33, 50.29, 73.67], marker='^', linestyle='--', label='EfficientNet B0')
ax.plot(x, [0, 0, 81.48], marker='8', linestyle='--', label='Xception')
ax.plot(x, [56.25, 77.85, 83.41], marker='x', linestyle='--', label='DenseNet')
ax.set_xticks(x)
ax.set_xticklabels(["$(32, 32, 3)$", "$(64, 64, 3)$", "$(96, 96, 3)$"])
ax.set_xlabel("Input Image Shape")
ax.set_ylabel("Test Set Accuracy (%)")
ax.legend(loc='lower right')
plt.show()